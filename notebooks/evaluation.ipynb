{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d70e71ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ansha\\Downloads\\split-bill-app-main\\Assignment_Rifqi Anshari Rasyid\\.venv\\lib\\site-packages\\google\\api_core\\_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.4) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import base64\n",
    "import mimetypes\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "085a1cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_pipeline(current_model):\n",
    "    client = ChatGoogleGenerativeAI(\n",
    "        model=current_model, \n",
    "        temperature=0,\n",
    "        max_retries=0\n",
    "    )\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95703235",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "You are given an image of a receipt. Please read the content into JSON format:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"items\": [\n",
    "        {\n",
    "            \"name\": <item name>,\n",
    "            \"quantity\": <item quantity>,\n",
    "            \"price_per_unit\": <item price per unit>\n",
    "        }\n",
    "    ],\n",
    "    \"service_price\": <service price in receipt or 0 if not available>,\n",
    "    \"tax_price\": <tax price in receipt or 0 if not available>,\n",
    "    \"discount_price\": <discount price in receipt or 0 if not available>,\n",
    "}\n",
    "```\n",
    "\n",
    "return only in JSON format\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc3276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_loader(current_image_path):\n",
    "    with open(current_image_path, \"rb\") as f:\n",
    "        image_bytes = f.read()\n",
    "\n",
    "    mime_type, _ = mimetypes.guess_type(current_image_path)\n",
    "    encoded = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "    image_uri = f\"data:{mime_type};base64,{encoded}\"\n",
    "    return image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "427a270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_pipeline(PROMPT, current_image_uri, current_client):\n",
    "    message = HumanMessage(\n",
    "        content=[\n",
    "            {\"type\": \"text\", \"text\": PROMPT},\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": current_image_uri},\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = current_client.invoke([message])\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    return response, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef52723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATHS = [r\"../data/receipt_1.jpg\", r\"../data/receipt_2.png\", r\"../data/receipt_3.jpg\"]\n",
    "MODELS_LIST = [\"gemini-2.5-flash\", \"gemini-2.0-flash\", \"gemini-2.0-flash-lite\"]\n",
    "n_trials = 3\n",
    "\n",
    "for current_model_name in MODELS_LIST:\n",
    "\n",
    "    for current_image_path in IMAGE_PATHS:\n",
    "        current_image_uri = image_loader(current_image_path)\n",
    "        \n",
    "        for current_trial in range(n_trials):\n",
    "            current_client = client_pipeline(model_name)\n",
    "            response, elapsed_time = inference_pipeline(PROMPT, current_image_uri, current_client)\n",
    "\n",
    "            with open(\"artifacts/evaluation_prompt.txt\", \"a+\") as file:\n",
    "                file.write(\"=\"*50 + \"\\n\")\n",
    "                file.write(f\"Evaluation for model: {current_model_name} on image: {current_image_path} on trial: {current_trial + 1}\\n\")\n",
    "                file.write(f\"Elapsed time: {elapsed_time}\\n\")\n",
    "                file.write(f\"Response: \\n{response.content}\\n\")\n",
    "\n",
    "            time.sleep(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
